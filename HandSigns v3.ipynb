{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with Tensorflow: HandSigns dataset application\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The assignment #2 at Coursera CNN Course (by Andrew Ng) showed 78.3% classification accuracy for recognizing hand signs data-set provided in the course.\n",
    "\n",
    "In this notebook, I implemented a simple Convolutional Neural Network in TensorFlow which has a classification accuracy of about >93%. \n",
    "\n",
    "My aim was to implement the CNN with a different Tensorflow graph. This code runs quite fast using a low-end GPU. The training data was acquired from the course at well.\n",
    "\n",
    "by Mehmet Solmaz, https://github.com/mesolmaz\n",
    "\n",
    "I benefited a lot from Hvass-Labs tensorflow tutorials (like using the Helper functions). Kudos to him: (https://github.com/Hvass-Labs/TensorFlow-Tutorials)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from cnn_utils import *\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the \"SIGNS\" dataset from current directory. You have to have registered for the course in order to obtain the H5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_classes\n",
      "train_set_x\n",
      "train_set_y\n",
      "list_classes\n",
      "test_set_x\n",
      "test_set_y\n"
     ]
    }
   ],
   "source": [
    "# Read H5 file\n",
    "f1 = h5py.File(\"train_signs.h5\", \"r\")\n",
    "# Get and print list of datasets within the H5 file\n",
    "datasetNames = [n for n in f1.keys()]\n",
    "for n in datasetNames:\n",
    "    print(n)\n",
    "    \n",
    "# Read H5 file\n",
    "f2 = h5py.File(\"test_signs.h5\", \"r\")\n",
    "# Get and print list of datasets within the H5 file\n",
    "datasetNames = [n for n in f2.keys()]\n",
    "for n in datasetNames:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Feature Size = (1080, 64, 64, 3)\n",
      "Training Data Class Size = (1080,)\n"
     ]
    }
   ],
   "source": [
    "# Loading the Training data (signs)\n",
    "X_train_orig = np.array(f1['train_set_x'])\n",
    "print (\"Training Data Feature Size = \" + str(X_train_orig.shape))\n",
    "Y_train_orig = np.array(f1['train_set_y'])\n",
    "print (\"Training Data Class Size = \" + str(Y_train_orig.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Feature Size = (120, 64, 64, 3)\n",
      "Test Data Class Size = (120,)\n"
     ]
    }
   ],
   "source": [
    "# Loading the Test data (signs)\n",
    "X_test_orig = np.array(f2['test_set_x'])\n",
    "print (\"Test Data Feature Size = \" + str(X_test_orig.shape))\n",
    "Y_test_orig = np.array(f2['test_set_y'])\n",
    "print (\"Test Data Class Size = \" + str(Y_test_orig.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_classes = (6,)\n"
     ]
    }
   ],
   "source": [
    "# How many hand signs (just to make sure, there should be 6)\n",
    "class_list = np.array(f2['list_classes'])\n",
    "print (\"list_classes = \" + str(class_list.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The image below was acquired from CNN Course on Coursera.__<br>\n",
    "The SIGNS dataset is a collection of 6 signs representing numbers from 0 to 5.\n",
    "\n",
    "<img src=\"images/SIGNS.png\" style=\"width:800px;height:300px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25789497470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture\n",
    "index = 29\n",
    "plt.imshow(X_train_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(Y_train_orig[index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_orig.dtype\n",
    "X_train = X_train_orig/255\n",
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "#X_train = X_train_orig/255.\n",
    "X_train = np.divide(X_train_orig,255)\n",
    "#X_test = X_test_orig/255.\n",
    "X_test = np.divide(X_test_orig,255)\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "conv_layers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that SIGNS images are 64 pixels in each dimension.\n",
    "img_size = 64\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale, 3 for RGB.\n",
    "num_channels = 3\n",
    "\n",
    "# Number of classes, total of 6 hand signs.\n",
    "num_classes = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for Weights and Bias initialization3\n",
    "The functions for Convolution+Pooling+Relu, Flattening layer, and Fully Connected Layer were all obtained from Hvass-Labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight Initialization\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(length):\n",
    "  initial = tf.constant(0.1, shape=[length])\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "# Helper-function for creating a new Convolutional Layer\n",
    "def new_conv_layer(input,              # The previous layer.\n",
    "                   num_input_channels, # Num. channels in prev. layer.\n",
    "                   filter_size,        # Width and height of each filter.\n",
    "                   num_filters,        # Number of filters.\n",
    "                   use_pooling=True):  # Use 2x2 max-pooling.\n",
    "\n",
    "    # Shape of the filter-weights for the convolution.\n",
    "    # This format is determined by the TensorFlow API.\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "    # Create new weights aka. filters with the given shape.\n",
    "    weights = weight_variable(shape=shape)\n",
    "\n",
    "    # Create new biases, one for each filter.\n",
    "    biases = bias_variable(length=num_filters)\n",
    "\n",
    "    # Create the TensorFlow operation for convolution.\n",
    "    # Note the strides are set to 1 in all dimensions.\n",
    "    # The first and last stride must always be 1,\n",
    "    # because the first is for the image-number and\n",
    "    # the last is for the input-channel.\n",
    "    # But e.g. strides=[1, 2, 2, 1] would mean that the filter\n",
    "    # is moved 2 pixels across the x- and y-axis of the image.\n",
    "    # The padding is set to 'SAME' which means the input image\n",
    "    # is padded with zeroes so the size of the output is the same.\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    # Add the biases to the results of the convolution.\n",
    "    # A bias-value is added to each filter-channel.\n",
    "    layer += biases\n",
    "\n",
    "    # Use pooling to down-sample the image resolution?\n",
    "    if use_pooling:\n",
    "        # This is 2x2 max-pooling, which means that we\n",
    "        # consider 2x2 windows and select the largest value\n",
    "        # in each window. Then we move 2 pixels to the next window.\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "\n",
    "    # Rectified Linear Unit (ReLU).\n",
    "    # It calculates max(x, 0) for each input pixel x.\n",
    "    # This adds some non-linearity to the formula and allows us\n",
    "    # to learn more complicated functions.\n",
    "    layer = tf.nn.relu(layer)\n",
    "\n",
    "    # Note that ReLU is normally executed before the pooling,\n",
    "    # but since relu(max_pool(x)) == max_pool(relu(x)) we can\n",
    "    # save 75% of the relu-operations by max-pooling first.\n",
    "\n",
    "    # We return both the resulting layer and the filter-weights\n",
    "    # because we will plot the weights later.\n",
    "    return layer, weights\n",
    "\n",
    "# Helper-function for flattening a layer\n",
    "def flatten_layer(layer):\n",
    "    # Get the shape of the input layer.\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    # The shape of the input layer is assumed to be:\n",
    "    # layer_shape == [num_images, img_height, img_width, num_channels]\n",
    "\n",
    "    # The number of features is: img_height * img_width * num_channels\n",
    "    # We can use a function from TensorFlow to calculate this.\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "    # Reshape the layer to [num_images, num_features].\n",
    "    # Note that we just set the size of the second dimension\n",
    "    # to num_features and the size of the first dimension to -1\n",
    "    # which means the size in that dimension is calculated\n",
    "    # so the total size of the tensor is unchanged from the reshaping.\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # The shape of the flattened layer is now:\n",
    "    # [num_images, img_height * img_width * num_channels]\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat, num_features\n",
    "\n",
    "# Helper-function for creating a new Fully-Connected Layer\n",
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,    # Num. outputs.\n",
    "                 use_relu=True): # Use Rectified Linear Unit (ReLU)?\n",
    "\n",
    "    # Create new weights and biases.\n",
    "    weights = weight_variable(shape=[num_inputs, num_outputs])\n",
    "    biases = bias_variable(length=num_outputs)\n",
    "\n",
    "    # Calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values.\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create placeholders\n",
    "\n",
    "TensorFlow requires that you create placeholders for the input data that will be fed into the model when running the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-b2e842b39b6b>:4: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "x = Tensor(\"x:0\", shape=(?, 4096), dtype=float32)\n",
      "y_true = Tensor(\"y_true:0\", shape=(?, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "#Y = tf.placeholder(tf.float32, shape=[None, 6])\n",
    "print (\"x = \" + str(x))\n",
    "print (\"y_true = \" + str(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for CONV1, CONV2 and FC layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 36         # There are 36 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 128             # Number of neurons in fully-connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv1, weights_conv1 = \\\n",
    "    new_conv_layer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 32, 32, 16) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv2, weights_conv2 = \\\n",
    "    new_conv_layer(input=layer_conv1,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_1:0' shape=(?, 16, 16, 36) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(?, 9216) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9216"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Fully-Connected Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_2:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Fully-Connected Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_3:0' shape=(?, 6) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted Class (Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost-function to be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Optimization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Run\n",
    "### Create TensorFlow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize variables\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-function to get a random training-batch\n",
    "There are 1080 images in the training-set. It is a good idea to use small batches of images in each iteration of the optimizer in case you run out of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch():\n",
    "    # Number of images in the training-set.\n",
    "    num_images = len(X_train)\n",
    "\n",
    "    # Create a random index.\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=train_batch_size,\n",
    "                           replace=False)\n",
    "\n",
    "    # Use the random index to select random images and labels.\n",
    "    x_batch = X_train[idx, :, :, :]\n",
    "    y_batch = Y_train[idx, :]\n",
    "\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-function to perform optimization iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter for total number of iterations performed so far.\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    # Ensure we update the global variable rather than a local copy.\n",
    "    global total_iterations\n",
    "\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        # x_batch, y_true_batch = tf.train.batch([X_train, Y_train], batch_size = train_batch_size)\n",
    "        # x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "        x_batch, y_true_batch = random_batch()\n",
    "\n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {x_image: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status every 100 iterations.\n",
    "        if i % 100 == 0:\n",
    "            # Calculate the accuracy on the training-set.\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "\n",
    "            # Message for printing.\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "\n",
    "            # Print it.\n",
    "            print(msg.format(i + 1, acc))\n",
    "\n",
    "    # Update the total number of iterations performed.\n",
    "    total_iterations += num_iterations\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-function to plot example errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example_errors(cls_pred, correct):\n",
    "    # This function is called from print_test_accuracy() below.\n",
    "\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # correct is a boolean array whether the predicted class\n",
    "    # is equal to the true class for each image in the test-set.\n",
    "\n",
    "    # Negate the boolean array.\n",
    "    incorrect = (correct == False)\n",
    "    \n",
    "    # Get the images from the test-set that have been\n",
    "    # incorrectly classified.\n",
    "    test_true = np.argmax(Y_test, axis=1)\n",
    "    images = test_true[incorrect]\n",
    "    \n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    cls_true = data.test_true.cls[incorrect]\n",
    "    \n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-function to plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cls_pred):\n",
    "    # This is called from print_test_accuracy() below.\n",
    "\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # Get the true classifications for the test-set.\n",
    "    cls_true = np.argmax(Y_test, axis=1)\n",
    "    \n",
    "    # Get the confusion matrix using sklearn.\n",
    "    cm = confusion_matrix(y_true=cls_true,\n",
    "                          y_pred=cls_pred)\n",
    "\n",
    "    # Print the confusion matrix as text.\n",
    "    print(cm)\n",
    "\n",
    "    # Plot the confusion matrix as an image.\n",
    "    plt.matshow(cm)\n",
    "\n",
    "    # Make various adjustments to the plot.\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, range(num_classes))\n",
    "    plt.yticks(tick_marks, range(num_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-function for showing the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test-set into smaller batches of this size.\n",
    "test_batch_size = 16\n",
    "\n",
    "def print_test_accuracy(show_example_errors=False,\n",
    "                        show_confusion_matrix=False):\n",
    "\n",
    "    # Number of images in the test-set.\n",
    "    num_test = len(X_test)\n",
    "\n",
    "    # Allocate an array for the predicted classes which\n",
    "    # will be calculated in batches and filled into this array.\n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "\n",
    "    # Now calculate the predicted classes for the batches.\n",
    "    # We will just iterate through all the batches.\n",
    "    # There might be a more clever and Pythonic way of doing this.\n",
    "\n",
    "    # The starting index for the next batch is denoted i.\n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "\n",
    "        # Get the images from the test-set between index i and j.\n",
    "        images = X_test[i:j,:,:,:]\n",
    "\n",
    "        # Get the associated labels.\n",
    "        labels = Y_test[i:j, :]\n",
    "\n",
    "        # Create a feed-dict with these images and labels.\n",
    "        feed_dict = {x_image: images,\n",
    "                     y_true: labels}\n",
    "\n",
    "        # Calculate the predicted class using TensorFlow.\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "\n",
    "        # Set the start-index for the next batch to the\n",
    "        # end-index of the current batch.\n",
    "        i = j\n",
    "\n",
    "    # Convenience variable for the true class-numbers of the test-set.\n",
    "    cls_true = np.argmax(Y_test, axis=1)\n",
    "\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = (cls_true == cls_pred)\n",
    "\n",
    "    # Calculate the number of correctly classified images.\n",
    "    # When summing a boolean array, False means 0 and True means 1.\n",
    "    correct_sum = correct.sum()\n",
    "\n",
    "    # Classification accuracy is the number of correctly classified\n",
    "    # images divided by the total number of images in the test-set.\n",
    "    acc = float(correct_sum) / num_test\n",
    "\n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, num_test))\n",
    "\n",
    "    # Plot some examples of mis-classifications, if desired.\n",
    "    if show_example_errors:\n",
    "        print(\"Example errors:\")\n",
    "        plot_example_errors(cls_pred=cls_pred, correct=correct)\n",
    "\n",
    "    # Plot the confusion matrix, if desired.\n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confusion Matrix:\")\n",
    "        plot_confusion_matrix(cls_pred=cls_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance after 2500 optimization iterations\n",
    "\n",
    "After 2500 optimization iterations, the model has significantly improved its classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:  17.2%\n",
      "Optimization Iteration:    101, Training Accuracy:  43.8%\n",
      "Optimization Iteration:    201, Training Accuracy:  59.4%\n",
      "Optimization Iteration:    301, Training Accuracy:  76.6%\n",
      "Optimization Iteration:    401, Training Accuracy:  81.2%\n",
      "Optimization Iteration:    501, Training Accuracy:  90.6%\n",
      "Optimization Iteration:    601, Training Accuracy:  95.3%\n",
      "Optimization Iteration:    701, Training Accuracy:  93.8%\n",
      "Optimization Iteration:    801, Training Accuracy:  95.3%\n",
      "Optimization Iteration:    901, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   1001, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   1101, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   1201, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   1301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   1401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   1501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   1601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   1701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   1801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   1901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2401, Training Accuracy: 100.0%\n",
      "Time usage: 0:03:51\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 93.3% (112 / 120)\n",
      "Confusion Matrix:\n",
      "[[20  0  0  0  0  0]\n",
      " [ 0 20  0  0  0  0]\n",
      " [ 0  2 17  0  0  1]\n",
      " [ 0  0  0 19  0  1]\n",
      " [ 0  0  0  1 17  2]\n",
      " [ 0  0  0  0  1 19]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25792cb3898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_test_accuracy(show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have High Variance (or Overfitting) the Training data. We can solve the Variance Problem using a Drop-out regularization. But I am not implementing that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "bwbJV",
   "launcher_item_id": "0TkXB"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
